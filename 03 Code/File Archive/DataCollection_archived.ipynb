{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pytrends pandas pandas_datareader request serpapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall serpapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords in different languages and regions\n",
    "keywords_by_region = {\n",
    "    'DE': [\n",
    "        \"Holzbearbeitungsmaschinen\", \"Möbelindustrie\", \"Holzhausbau\", \"Möbel\", \"Haus\", \"Küche\",\n",
    "        \"Möbelherstellung Maschinen\", \"Küchenmöbel Produktion\", \"CNC Holzbearbeitungsmaschinen\",\"Automatisierte Möbelproduktion\", \"Holzverarbeitungsanlagen\", \"Nachhaltige Möbelproduktion\",\n",
    "        \"Möbeldesign Trends\", \"Küchenmöbel Trends\", \"Holzwerkstoffe\", \"DIY Möbelbau\", \"Innenausbau Trends\", \"Smart Home Möbel\", \"3D-Druck Möbel\", \"Modulare Holzhäuser\", \"Holzbau Technologien\", \"Holzwerkzeug Maschinen\", \"Holzverarbeitende Industrie\"\n",
    "    ],\n",
    "    'US': [\n",
    "        \"woodworking machines\", \"furniture industry\", \"wooden house construction\", \"furniture\", \"house\", \"kitchen\",\"furniture manufacturing machines\", \"kitchen furniture production\", \"CNC woodworking machines\", \"automated furniture production\", \"wood processing plants\", \"sustainable furniture production\", \"furniture design trends\", \"kitchen furniture trends\", \"wood materials\", \"DIY furniture building\", \"interior design trends\", \"smart home furniture\", \"3D printed furniture\", \"modular wooden houses\", \"wood construction technologies\", \"woodworking tools\", \"wood processing industry\"\n",
    "    ],\n",
    "    'FR': [\n",
    "        \"Machines à bois\", \"Industrie du meuble\", \"Construction de maisons en bois\", \"Meubles\", \"Maison\", \"Cuisine\",\n",
    "        \"Machines de fabrication de meubles\", \"Production de meubles de cuisine\", \"Machines CNC pour le travail du bois\", \"Production automatisée de meubles\", \"Installations de transformation du bois\", \"Production de meubles durables\", \"Tendances du design de meubles\", \"Tendances des meubles de cuisine\", \"Matériaux en bois\", \"Construction de meubles DIY\", \"Tendances de l'aménagement intérieur\", \"Meubles intelligents\", \"Meubles imprimés en 3D\", \"Maisons en bois modulaires\", \"Technologies de construction en bois\", \"Outils de travail du bois\", \"Industrie de la transformation du bois\"\n",
    "    ],\n",
    "    'ES': [\n",
    "        \"Máquinas para trabajar la madera\", \"Industria del mueble\", \"Construcción de casas de madera\", \"Muebles\", \"Casa\", \"Cocina\", \"Máquinas de fabricación de muebles\", \"Producción de muebles de cocina\", \"Máquinas CNC para trabajar la madera\", \"Producción automatizada de muebles\", \"Plantas de procesamiento de madera\", \"Producción sostenible de muebles\", \"Tendencias en diseño de muebles\", \"Tendencias en muebles de cocina\", \"Materiales de madera\", \"Construcción de muebles DIY\", \"Tendencias en diseño de interiores\", \"Muebles inteligentes\", \"Muebles impresos en 3D\", \"Casas de madera modulares\", \"Tecnologías de construcción en madera\", \"Herramientas para trabajar la madera\", \"Industria de procesamiento de madera\"\n",
    "    ],\n",
    "    'IT': [\n",
    "        \"Macchine per la lavorazione del legno\", \"Industria del mobile\", \"Costruzione di case in legno\", \"Mobili\", \"Casa\", \"Cucina\", \"Macchine per la fabbricazione di mobili\", \"Produzione di mobili da cucina\", \"Macchine CNC per la lavorazione del legno\", \"Produzione automatizzata di mobili\", \"Impianti di lavorazione del legno\", \"Produzione sostenibile di mobili\", \"Tendenze del design dei mobili\", \"Tendenze dei mobili da cucina\", \"Materiali in legno\", \"Costruzione di mobili DIY\", \"Tendenze di interior design\", \"Mobili intelligenti\", \"Mobili stampati in 3D\", \"Case in legno modulari\", \"Tecnologie di costruzione in legno\", \"Utensili per la lavorazione del legno\", \"Industria della lavorazione del legno\"\n",
    "    ],\n",
    "    'PT': [\n",
    "        \"Máquinas para trabalhar madeira\", \"Indústria de móveis\", \"Construção de casas de madeira\", \"Móveis\", \"Casa\", \"Cozinha\", \"Máquinas de fabricação de móveis\", \"Produção de móveis de cozinha\", \"Máquinas CNC para trabalhar madeira\", \"Produção automatizada de móveis\", \"Plantas de processamento de madeira\", \"Produção sustentável de móveis\", \"Tendências de design de móveis\", \"Tendências de móveis de cozinha\", \"Materiais de madeira\", \"Construção de móveis DIY\", \"Tendências de design de interiores\", \"Móveis inteligentes\", \"Móveis impressos em 3D\", \"Casas de madeira modulares\", \"Tecnologias de construção em madeira\", \"Ferramentas para trabalhar madeira\", \"Indústria de processamento de madeira\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TooManyRequestsError",
     "evalue": "The request failed: Google returned a response with code 429",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m pytrend \u001b[38;5;241m=\u001b[39m TrendReq()\n\u001b[0;32m      5\u001b[0m pytrend\u001b[38;5;241m.\u001b[39mbuild_payload(kw_list\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFurniture\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpytrend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterest_over_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tb10muj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytrends\\request.py:232\u001b[0m, in \u001b[0;36mTrendReq.interest_over_time\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m over_time_payload \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# convert to string as requests will mangle\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreq\u001b[39m\u001b[38;5;124m'\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterest_over_time_widget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterest_over_time_widget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtz\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtz\n\u001b[0;32m    229\u001b[0m }\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# make the request and parse the returned json\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m req_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTEREST_OVER_TIME_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_METHOD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrim_chars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mover_time_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(req_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimelineData\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (df\u001b[38;5;241m.\u001b[39mempty):\n",
      "File \u001b[1;32mc:\\Users\\tb10muj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytrends\\request.py:159\u001b[0m, in \u001b[0;36mTrendReq._get_data\u001b[1;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m status_codes\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mtoo_many_requests:\n\u001b[1;32m--> 159\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTooManyRequestsError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mResponseError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "\u001b[1;31mTooManyRequestsError\u001b[0m: The request failed: Google returned a response with code 429"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "\n",
    "pytrend = TrendReq()\n",
    "pytrend.build_payload(kw_list=['Furniture'])\n",
    "\n",
    "df = pytrend.interest_over_time()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Example pytrends\n",
    "\n",
    "import pandas as pd                        \n",
    "from pytrends.request import TrendReq\n",
    "pytrends = TrendReq(hl='en-US', tz=360, timeout=(10,25), \n",
    "                    #proxies=['https://34.203.233.13:80',],\n",
    "                    retries=2, backoff_factor=0.1, requests_args={'verify':False})\n",
    "\n",
    "pytrend.build_payload(kw_list=['Furniture'], timeframe='2023-06-01 2024-06-30',geo='DE')\n",
    "# Interest by Region\n",
    "df = pytrend.interest_over_time()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serpapi\n",
    "\n",
    "# Listet alle Attribute und Methoden im serpapi-Modul auf\n",
    "print(dir(serpapi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Example SerpApi\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "params = {\n",
    "  \"engine\": \"google_trends\",\n",
    "  \"q\": \"Furniture, kitchen\",\n",
    "  \"data_type\": \"TIMESERIES\",\n",
    "  \"date\": \"today 5-y\",\n",
    "  \"api_key\": \"secret_api_key\"\n",
    "}\n",
    "\n",
    "search = GoogleSearch(params)\n",
    "results = search.get_dict()\n",
    "interest_over_time = results[\"interest_over_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "The request failed: Google returned a response with code 400",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 103\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_data\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Fetch the data\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m all_trends_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_trends\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpytrends\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeywords_by_region\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Save the fetched data to CSV files\u001b[39;00m\n\u001b[0;32m    106\u001b[0m save_data_to_csv(all_trends_data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle_trends_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[51], line 22\u001b[0m, in \u001b[0;36mget_trends\u001b[1;34m(pytrends, keywords_by_region)\u001b[0m\n\u001b[0;32m     11\u001b[0m all_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterest_over_time\u001b[39m\u001b[38;5;124m'\u001b[39m: pd\u001b[38;5;241m.\u001b[39mDataFrame(),\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrending_searches\u001b[39m\u001b[38;5;124m'\u001b[39m: pd\u001b[38;5;241m.\u001b[39mDataFrame(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrealtime_trending_searches\u001b[39m\u001b[38;5;124m'\u001b[39m: pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m     19\u001b[0m }\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m region, keywords \u001b[38;5;129;01min\u001b[39;00m keywords_by_region\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mpytrends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_payload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoday 5-y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;66;03m# Interest over time\u001b[39;00m\n\u001b[0;32m     26\u001b[0m         interest_over_time \u001b[38;5;241m=\u001b[39m pytrends\u001b[38;5;241m.\u001b[39minterest_over_time()\n",
      "File \u001b[1;32mc:\\Users\\tb10muj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytrends\\request.py:189\u001b[0m, in \u001b[0;36mTrendReq.build_payload\u001b[1;34m(self, kw_list, cat, timeframe, geo, gprop)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_payload[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_payload[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# get tokens\u001b[39;00m\n\u001b[1;32m--> 189\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tb10muj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytrends\\request.py:195\u001b[0m, in \u001b[0;36mTrendReq._tokens\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Makes request to Google to get API tokens for interest over time, interest by region and related queries\"\"\"\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# make the request and parse the returned json\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m widget_dicts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGENERAL_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOST_METHOD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrim_chars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidgets\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# order of the json matters...\u001b[39;00m\n\u001b[0;32m    202\u001b[0m first_region_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tb10muj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytrends\\request.py:160\u001b[0m, in \u001b[0;36mTrendReq._get_data\u001b[1;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m status_codes\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mtoo_many_requests:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTooManyRequestsError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m--> 160\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mResponseError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "\u001b[1;31mResponseError\u001b[0m: The request failed: Google returned a response with code 400"
     ]
    }
   ],
   "source": [
    "# PyTrends Google Trends Scraping\n",
    "\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Initialize\n",
    "pytrends = TrendReq()\n",
    "\n",
    "def get_trends(pytrends, keywords_by_region):\n",
    "    all_data = {\n",
    "        'interest_over_time': pd.DataFrame(),\n",
    "        'trending_searches': pd.DataFrame(),\n",
    "        'related_topics': pd.DataFrame(),\n",
    "        'related_queries': pd.DataFrame(),\n",
    "        'interest_by_region': pd.DataFrame(),\n",
    "        'historical_interest': pd.DataFrame(),\n",
    "        'realtime_trending_searches': pd.DataFrame()\n",
    "    }\n",
    "    \n",
    "    for region, keywords in keywords_by_region.items():\n",
    "        pytrends.build_payload(keywords, timeframe='today 5-y', geo=region)\n",
    "\n",
    "        try:\n",
    "            # Interest over time\n",
    "            interest_over_time = pytrends.interest_over_time()\n",
    "            if not interest_over_time.empty:\n",
    "                interest_over_time['Region'] = region\n",
    "                all_data['interest_over_time'] = pd.concat([all_data['interest_over_time'], interest_over_time])\n",
    "            time.sleep(60)  # Pause for 60 seconds to avoid hitting request limit\n",
    "            \n",
    "            # Trending searches\n",
    "            trending_searches = pytrends.trending_searches(pn=region)\n",
    "            trending_searches['Region'] = region\n",
    "            all_data['trending_searches'] = pd.concat([all_data['trending_searches'], trending_searches])\n",
    "            time.sleep(60)  # Pause for 60 seconds to avoid hitting request limit\n",
    "            \n",
    "            # Related topics\n",
    "            related_topics = pytrends.related_topics()\n",
    "            for kw, df in related_topics.items():\n",
    "                if df['top'] is not None:\n",
    "                    df['top']['Region'] = region\n",
    "                    df['top']['Keyword'] = kw\n",
    "                    all_data['related_topics'] = pd.concat([all_data['related_topics'], df['top']])\n",
    "            time.sleep(60)  # Pause for 60 seconds to avoid hitting request limit\n",
    "            \n",
    "            # Related queries\n",
    "            related_queries = pytrends.related_queries()\n",
    "            for kw, df in related_queries.items():\n",
    "                if df['top'] is not None:\n",
    "                    df['top']['Region'] = region\n",
    "                    df['top']['Keyword'] = kw\n",
    "                    all_data['related_queries'] = pd.concat([all_data['related_queries'], df['top']])\n",
    "            time.sleep(60)  # Pause for 60 seconds to avoid hitting request limit\n",
    "            \n",
    "            # Interest by region\n",
    "            interest_by_region = pytrends.interest_by_region()\n",
    "            if not interest_by_region.empty:\n",
    "                interest_by_region['Region'] = region\n",
    "                all_data['interest_by_region'] = pd.concat([all_data['interest_by_region'], interest_by_region])\n",
    "            time.sleep(60)  # Pause for 60 seconds to avoid hitting request limit\n",
    "\n",
    "            # Historical interest\n",
    "            historical_interest = pytrends.get_historical_interest(keywords, year_start=2018, month_start=1, day_start=1, year_end=2023, month_end=1, day_end=1, geo=region)\n",
    "            if not historical_interest.empty:\n",
    "                historical_interest['Region'] = region\n",
    "                all_data['historical_interest'] = pd.concat([all_data['historical_interest'], historical_interest])\n",
    "            time.sleep(60)  # Pause for 60 seconds to avoid hitting request limit\n",
    "            \n",
    "            # Realtime trending searches\n",
    "            realtime_trending_searches = pytrends.realtime_trending_searches(pn=region)\n",
    "            realtime_trending_searches['Region'] = region\n",
    "            all_data['realtime_trending_searches'] = pd.concat([all_data['realtime_trending_searches'], realtime_trending_searches])\n",
    "            time.sleep(60)  # Pause for 60 seconds to avoid hitting request limit\n",
    "            \n",
    "            print(f\"Successfully fetched data for region: {region}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for region {region}: {e}\")\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def save_data_to_csv(all_data, filename_prefix):\n",
    "    for data_type, df in all_data.items():\n",
    "        if not df.empty:\n",
    "            df.to_csv(f\"{filename_prefix}_{data_type}.csv\", index=False)\n",
    "            print(f\"Saved {data_type} data to {filename_prefix}_{data_type}.csv\")\n",
    "\n",
    "def read_data_from_csv(filename_prefix):\n",
    "    data_types = ['interest_over_time', 'trending_searches', 'related_topics', 'related_queries', 'interest_by_region', 'historical_interest', 'realtime_trending_searches']\n",
    "    all_data = {}\n",
    "    for data_type in data_types:\n",
    "        filename = f\"{filename_prefix}_{data_type}.csv\"\n",
    "        try:\n",
    "            df = pd.read_csv(filename)\n",
    "            all_data[data_type] = df\n",
    "            print(f\"Read {data_type} data from {filename}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"{filename} not found.\")\n",
    "            all_data[data_type] = pd.DataFrame()\n",
    "    return all_data\n",
    "\n",
    "# Fetch the data\n",
    "all_trends_data = get_trends(pytrends, keywords_by_region)\n",
    "\n",
    "# Save the fetched data to CSV files\n",
    "save_data_to_csv(all_trends_data, \"google_trends_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the data back from CSV files\n",
    "loaded_data = read_data_from_csv(\"google_trends_data\")\n",
    "\n",
    "# Output the loaded data\n",
    "for data_type, df in loaded_data.items():\n",
    "    print(f\"\\nData Type: {data_type}\")\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "def fetch_oecd_data(dataset, indicator, start_year, end_year):\n",
    "    query = f\"{indicator}.AUS+AUT+BEL+CAN\"\n",
    "    data = web.DataReader(f\"OECD/{dataset}/{query}\", 'oecd', start=start_year, end=end_year)\n",
    "    return data\n",
    "\n",
    "dataset = \"QNA\"\n",
    "indicator = \"B1_GE.CUR+VOBARSA.Q\"\n",
    "start_year = 2015\n",
    "end_year = 2020\n",
    "\n",
    "data = fetch_oecd_data(dataset, indicator, start_year, end_year)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten wurden erfolgreich abgerufen und gespeichert.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Definieren Sie die URL\n",
    "url = \"https://sdmx.oecd.org/public/rest/dataflow/OECD.SDD.NAD/DSD_NAAG@DF_NAAG_VII/1.0?references=all\"\n",
    "\n",
    "# Senden Sie eine GET-Anfrage an die URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Überprüfen Sie den Statuscode der Antwort\n",
    "if response.status_code == 200:\n",
    "    # Wenn die Anfrage erfolgreich war, drucken Sie den Inhalt der Antwort\n",
    "    data = response.content\n",
    "    \n",
    "    # Sie können die Daten in einer Datei speichern oder weiterverarbeiten\n",
    "    with open('data.xml', 'wb') as file:\n",
    "        file.write(data)\n",
    "        \n",
    "    print(\"Daten wurden erfolgreich abgerufen und gespeichert.\")\n",
    "else:\n",
    "    print(f\"Fehler beim Abrufen der Daten. Statuscode: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def fetch_and_display_data(url):\n",
    "    # Senden Sie eine GET-Anfrage an die URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Überprüfen Sie den Statuscode der Antwort\n",
    "    if response.status_code == 200:\n",
    "        # Wenn die Anfrage erfolgreich war, parsen Sie die XML-Daten\n",
    "        root = ET.fromstring(response.content)\n",
    "        \n",
    "        # Eine einfache Funktion zum rekursiven Durchlaufen und Darstellen der XML-Daten\n",
    "        def print_element(element, indent=0):\n",
    "            print(f\"{' ' * indent}{element.tag}: {element.text}\")\n",
    "            for child in element:\n",
    "                print_element(child, indent + 2)\n",
    "        \n",
    "        # Starten Sie die Darstellung vom Wurzelelement\n",
    "        print_element(root)\n",
    "        \n",
    "        print(\"Daten wurden erfolgreich abgerufen und dargestellt.\")\n",
    "    else:\n",
    "        print(f\"Fehler beim Abrufen der Daten. Statuscode: {response.status_code}\")\n",
    "\n",
    "# Definieren Sie die URL\n",
    "url = \"https://sdmx.oecd.org/public/rest/dataflow/OECD.SDD.NAD/DSD_NAAG@DF_NAAG_VII/1.0?references=all\"\n",
    "\n",
    "# Rufen Sie die Funktion auf\n",
    "fetch_and_display_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.oecd as oecd\n",
    "import datetime\n",
    "\n",
    "# Definieren Sie den Zeitraum für die Daten, die Sie abrufen möchten\n",
    "start = datetime.datetime(2020, 1, 1)\n",
    "end = datetime.datetime(2023, 1, 1)\n",
    "\n",
    "# Abfrage der OECD Composite Leading Indicators (CLI)\n",
    "# Ländercode (z.B. \"USA\" für die Vereinigten Staaten) und Indikatorcode (z.B. \"LOLITOAA\" für CLI) anpassen\n",
    "country = \"USA\"\n",
    "indicator = \"LOLITOAA\"\n",
    "\n",
    "# Holen Sie sich die Daten\n",
    "reader = oecd.OECDReader('MEI_CLI', start, end)\n",
    "\n",
    "df = reader.read()\n",
    "\n",
    "# Anzeigen der abgerufenen Daten\n",
    "df.columns\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Definieren Sie den Zeitraum für die Daten, die Sie abrufen möchten\n",
    "start_date = '2020-01'\n",
    "end_date = '2023-01'\n",
    "\n",
    "# Definieren Sie den OECD-API-Endpunkt und die Parameter\n",
    "base_url = 'https://stats.oecd.org/SDMX-JSON/data/'\n",
    "dataset = 'MEI_CLI'\n",
    "location = 'USA'\n",
    "subject = 'LOLITOAA'\n",
    "measure = 'GYSA'\n",
    "frequency = 'M'\n",
    "\n",
    "# Erstellen Sie die vollständige URL für die API-Anfrage\n",
    "url = f\"{base_url}{dataset}/{location}.{subject}.{measure}.{frequency}/all?startTime={start_date}&endTime={end_date}\"\n",
    "\n",
    "# Senden Sie die HTTP-Anfrage an die OECD-API\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Überprüfen Sie, ob die Anfrage erfolgreich war\n",
    "\n",
    "# Analysieren Sie die JSON-Antwort\n",
    "data = response.json()\n",
    "\n",
    "# Extrahieren Sie die relevanten Daten\n",
    "observations = data['dataSets'][0]['observations']\n",
    "dates = list(data['structure']['dimensions']['observation'][0]['values'])\n",
    "values = []\n",
    "\n",
    "# Erstellen Sie eine Liste von Datumswerten und Beobachtungen\n",
    "for key, value in observations.items():\n",
    "    date_index = int(key.split(':')[0])\n",
    "    date = dates[date_index]['id']\n",
    "    values.append((date, value[0]))\n",
    "\n",
    "# Erstellen Sie ein pandas DataFrame\n",
    "df = pd.DataFrame(values, columns=['Date', 'Value'])\n",
    "\n",
    "# Konvertieren Sie die Datumswerte in ein pandas Datetime-Format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Setzen Sie die Spalte \"Date\" als Index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Anzeigen der abgerufenen Daten\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenintegration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammenführen der Daten:\n",
    "# Google Trends: Interest over Time und by Region\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
